{"cells":[{"cell_type":"markdown","metadata":{"id":"ZRFU55UCiuMM"},"source":["# Neural Network Embeddings as Feature Vectors\n","\n","In this exercise, you will load the weights of a pre-trained network and pass an image through the network to get the resulting embedding vector. This output can then be used as a feature vector for any classifier.\n","\n","We are going to use the [ResNet50](https://pytorch.org/vision/stable/models.html) pre-trained network, which has been loaded for you below."]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":15936,"status":"ok","timestamp":1708621547282,"user":{"displayName":"Rachel Brown","userId":"06073861844932952956"},"user_tz":480},"id":"FLj2TrQ8Rzom"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","\n","from glob import glob\n","\n","from PIL import Image\n","from torch import nn\n","import torchvision.models as models\n","from torchvision import transforms\n","from torchsummary import summary\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.pipeline import make_pipeline\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.svm import SVC\n","\n","import seaborn as sn\n","from sklearn.metrics import confusion_matrix"]},{"cell_type":"markdown","metadata":{"id":"7HOGjGUoj58j"},"source":["# Part 1 -- Extract Embedding Features From A Single Image"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":180,"status":"ok","timestamp":1708621596153,"user":{"displayName":"Rachel Brown","userId":"06073861844932952956"},"user_tz":480},"id":"fPeq3iIEtg0P","outputId":"bf19e4e6-3d12-4e9a-fd32-e35fa82a9c1c"},"outputs":[{"name":"stdout","output_type":"stream","text":["['buildings', 'forest', 'glacier', 'mountain', 'sea', 'street']\n"]}],"source":["# Path to Dataset\n","root_path = '../image_classification/Intel Training Dataset/'\n","\n","# split into subfolders based on class label\n","subfolders = sorted(glob(root_path + '*'))\n","label_names = [p.split('/')[-1] for p in subfolders]\n","\n","label_names = []\n","for p in subfolders:\n","  label_names.append(p.split('/')[-1])\n","\n","print(label_names)"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"prpf27WcjNYp"},"outputs":[{"name":"stderr","output_type":"stream","text":["/Users/rowedaniel/Documents/school/CS-369-AI/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/Users/rowedaniel/Documents/school/CS-369-AI/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n"]},{"name":"stdout","output_type":"stream","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1         [-1, 64, 112, 112]           9,408\n","       BatchNorm2d-2         [-1, 64, 112, 112]             128\n","              ReLU-3         [-1, 64, 112, 112]               0\n","         MaxPool2d-4           [-1, 64, 56, 56]               0\n","            Conv2d-5           [-1, 64, 56, 56]           4,096\n","       BatchNorm2d-6           [-1, 64, 56, 56]             128\n","              ReLU-7           [-1, 64, 56, 56]               0\n","            Conv2d-8           [-1, 64, 56, 56]          36,864\n","       BatchNorm2d-9           [-1, 64, 56, 56]             128\n","             ReLU-10           [-1, 64, 56, 56]               0\n","           Conv2d-11          [-1, 256, 56, 56]          16,384\n","      BatchNorm2d-12          [-1, 256, 56, 56]             512\n","           Conv2d-13          [-1, 256, 56, 56]          16,384\n","      BatchNorm2d-14          [-1, 256, 56, 56]             512\n","             ReLU-15          [-1, 256, 56, 56]               0\n","       Bottleneck-16          [-1, 256, 56, 56]               0\n","           Conv2d-17           [-1, 64, 56, 56]          16,384\n","      BatchNorm2d-18           [-1, 64, 56, 56]             128\n","             ReLU-19           [-1, 64, 56, 56]               0\n","           Conv2d-20           [-1, 64, 56, 56]          36,864\n","      BatchNorm2d-21           [-1, 64, 56, 56]             128\n","             ReLU-22           [-1, 64, 56, 56]               0\n","           Conv2d-23          [-1, 256, 56, 56]          16,384\n","      BatchNorm2d-24          [-1, 256, 56, 56]             512\n","             ReLU-25          [-1, 256, 56, 56]               0\n","       Bottleneck-26          [-1, 256, 56, 56]               0\n","           Conv2d-27           [-1, 64, 56, 56]          16,384\n","      BatchNorm2d-28           [-1, 64, 56, 56]             128\n","             ReLU-29           [-1, 64, 56, 56]               0\n","           Conv2d-30           [-1, 64, 56, 56]          36,864\n","      BatchNorm2d-31           [-1, 64, 56, 56]             128\n","             ReLU-32           [-1, 64, 56, 56]               0\n","           Conv2d-33          [-1, 256, 56, 56]          16,384\n","      BatchNorm2d-34          [-1, 256, 56, 56]             512\n","             ReLU-35          [-1, 256, 56, 56]               0\n","       Bottleneck-36          [-1, 256, 56, 56]               0\n","           Conv2d-37          [-1, 128, 56, 56]          32,768\n","      BatchNorm2d-38          [-1, 128, 56, 56]             256\n","             ReLU-39          [-1, 128, 56, 56]               0\n","           Conv2d-40          [-1, 128, 28, 28]         147,456\n","      BatchNorm2d-41          [-1, 128, 28, 28]             256\n","             ReLU-42          [-1, 128, 28, 28]               0\n","           Conv2d-43          [-1, 512, 28, 28]          65,536\n","      BatchNorm2d-44          [-1, 512, 28, 28]           1,024\n","           Conv2d-45          [-1, 512, 28, 28]         131,072\n","      BatchNorm2d-46          [-1, 512, 28, 28]           1,024\n","             ReLU-47          [-1, 512, 28, 28]               0\n","       Bottleneck-48          [-1, 512, 28, 28]               0\n","           Conv2d-49          [-1, 128, 28, 28]          65,536\n","      BatchNorm2d-50          [-1, 128, 28, 28]             256\n","             ReLU-51          [-1, 128, 28, 28]               0\n","           Conv2d-52          [-1, 128, 28, 28]         147,456\n","      BatchNorm2d-53          [-1, 128, 28, 28]             256\n","             ReLU-54          [-1, 128, 28, 28]               0\n","           Conv2d-55          [-1, 512, 28, 28]          65,536\n","      BatchNorm2d-56          [-1, 512, 28, 28]           1,024\n","             ReLU-57          [-1, 512, 28, 28]               0\n","       Bottleneck-58          [-1, 512, 28, 28]               0\n","           Conv2d-59          [-1, 128, 28, 28]          65,536\n","      BatchNorm2d-60          [-1, 128, 28, 28]             256\n","             ReLU-61          [-1, 128, 28, 28]               0\n","           Conv2d-62          [-1, 128, 28, 28]         147,456\n","      BatchNorm2d-63          [-1, 128, 28, 28]             256\n","             ReLU-64          [-1, 128, 28, 28]               0\n","           Conv2d-65          [-1, 512, 28, 28]          65,536\n","      BatchNorm2d-66          [-1, 512, 28, 28]           1,024\n","             ReLU-67          [-1, 512, 28, 28]               0\n","       Bottleneck-68          [-1, 512, 28, 28]               0\n","           Conv2d-69          [-1, 128, 28, 28]          65,536\n","      BatchNorm2d-70          [-1, 128, 28, 28]             256\n","             ReLU-71          [-1, 128, 28, 28]               0\n","           Conv2d-72          [-1, 128, 28, 28]         147,456\n","      BatchNorm2d-73          [-1, 128, 28, 28]             256\n","             ReLU-74          [-1, 128, 28, 28]               0\n","           Conv2d-75          [-1, 512, 28, 28]          65,536\n","      BatchNorm2d-76          [-1, 512, 28, 28]           1,024\n","             ReLU-77          [-1, 512, 28, 28]               0\n","       Bottleneck-78          [-1, 512, 28, 28]               0\n","           Conv2d-79          [-1, 256, 28, 28]         131,072\n","      BatchNorm2d-80          [-1, 256, 28, 28]             512\n","             ReLU-81          [-1, 256, 28, 28]               0\n","           Conv2d-82          [-1, 256, 14, 14]         589,824\n","      BatchNorm2d-83          [-1, 256, 14, 14]             512\n","             ReLU-84          [-1, 256, 14, 14]               0\n","           Conv2d-85         [-1, 1024, 14, 14]         262,144\n","      BatchNorm2d-86         [-1, 1024, 14, 14]           2,048\n","           Conv2d-87         [-1, 1024, 14, 14]         524,288\n","      BatchNorm2d-88         [-1, 1024, 14, 14]           2,048\n","             ReLU-89         [-1, 1024, 14, 14]               0\n","       Bottleneck-90         [-1, 1024, 14, 14]               0\n","           Conv2d-91          [-1, 256, 14, 14]         262,144\n","      BatchNorm2d-92          [-1, 256, 14, 14]             512\n","             ReLU-93          [-1, 256, 14, 14]               0\n","           Conv2d-94          [-1, 256, 14, 14]         589,824\n","      BatchNorm2d-95          [-1, 256, 14, 14]             512\n","             ReLU-96          [-1, 256, 14, 14]               0\n","           Conv2d-97         [-1, 1024, 14, 14]         262,144\n","      BatchNorm2d-98         [-1, 1024, 14, 14]           2,048\n","             ReLU-99         [-1, 1024, 14, 14]               0\n","      Bottleneck-100         [-1, 1024, 14, 14]               0\n","          Conv2d-101          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-102          [-1, 256, 14, 14]             512\n","            ReLU-103          [-1, 256, 14, 14]               0\n","          Conv2d-104          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-105          [-1, 256, 14, 14]             512\n","            ReLU-106          [-1, 256, 14, 14]               0\n","          Conv2d-107         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-108         [-1, 1024, 14, 14]           2,048\n","            ReLU-109         [-1, 1024, 14, 14]               0\n","      Bottleneck-110         [-1, 1024, 14, 14]               0\n","          Conv2d-111          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-112          [-1, 256, 14, 14]             512\n","            ReLU-113          [-1, 256, 14, 14]               0\n","          Conv2d-114          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-115          [-1, 256, 14, 14]             512\n","            ReLU-116          [-1, 256, 14, 14]               0\n","          Conv2d-117         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-118         [-1, 1024, 14, 14]           2,048\n","            ReLU-119         [-1, 1024, 14, 14]               0\n","      Bottleneck-120         [-1, 1024, 14, 14]               0\n","          Conv2d-121          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-122          [-1, 256, 14, 14]             512\n","            ReLU-123          [-1, 256, 14, 14]               0\n","          Conv2d-124          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-125          [-1, 256, 14, 14]             512\n","            ReLU-126          [-1, 256, 14, 14]               0\n","          Conv2d-127         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-128         [-1, 1024, 14, 14]           2,048\n","            ReLU-129         [-1, 1024, 14, 14]               0\n","      Bottleneck-130         [-1, 1024, 14, 14]               0\n","          Conv2d-131          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-132          [-1, 256, 14, 14]             512\n","            ReLU-133          [-1, 256, 14, 14]               0\n","          Conv2d-134          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-135          [-1, 256, 14, 14]             512\n","            ReLU-136          [-1, 256, 14, 14]               0\n","          Conv2d-137         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-138         [-1, 1024, 14, 14]           2,048\n","            ReLU-139         [-1, 1024, 14, 14]               0\n","      Bottleneck-140         [-1, 1024, 14, 14]               0\n","          Conv2d-141          [-1, 512, 14, 14]         524,288\n","     BatchNorm2d-142          [-1, 512, 14, 14]           1,024\n","            ReLU-143          [-1, 512, 14, 14]               0\n","          Conv2d-144            [-1, 512, 7, 7]       2,359,296\n","     BatchNorm2d-145            [-1, 512, 7, 7]           1,024\n","            ReLU-146            [-1, 512, 7, 7]               0\n","          Conv2d-147           [-1, 2048, 7, 7]       1,048,576\n","     BatchNorm2d-148           [-1, 2048, 7, 7]           4,096\n","          Conv2d-149           [-1, 2048, 7, 7]       2,097,152\n","     BatchNorm2d-150           [-1, 2048, 7, 7]           4,096\n","            ReLU-151           [-1, 2048, 7, 7]               0\n","      Bottleneck-152           [-1, 2048, 7, 7]               0\n","          Conv2d-153            [-1, 512, 7, 7]       1,048,576\n","     BatchNorm2d-154            [-1, 512, 7, 7]           1,024\n","            ReLU-155            [-1, 512, 7, 7]               0\n","          Conv2d-156            [-1, 512, 7, 7]       2,359,296\n","     BatchNorm2d-157            [-1, 512, 7, 7]           1,024\n","            ReLU-158            [-1, 512, 7, 7]               0\n","          Conv2d-159           [-1, 2048, 7, 7]       1,048,576\n","     BatchNorm2d-160           [-1, 2048, 7, 7]           4,096\n","            ReLU-161           [-1, 2048, 7, 7]               0\n","      Bottleneck-162           [-1, 2048, 7, 7]               0\n","          Conv2d-163            [-1, 512, 7, 7]       1,048,576\n","     BatchNorm2d-164            [-1, 512, 7, 7]           1,024\n","            ReLU-165            [-1, 512, 7, 7]               0\n","          Conv2d-166            [-1, 512, 7, 7]       2,359,296\n","     BatchNorm2d-167            [-1, 512, 7, 7]           1,024\n","            ReLU-168            [-1, 512, 7, 7]               0\n","          Conv2d-169           [-1, 2048, 7, 7]       1,048,576\n","     BatchNorm2d-170           [-1, 2048, 7, 7]           4,096\n","            ReLU-171           [-1, 2048, 7, 7]               0\n","      Bottleneck-172           [-1, 2048, 7, 7]               0\n","AdaptiveAvgPool2d-173           [-1, 2048, 1, 1]               0\n","================================================================\n","Total params: 23,508,032\n","Trainable params: 23,508,032\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.57\n","Forward/backward pass size (MB): 286.55\n","Params size (MB): 89.68\n","Estimated Total Size (MB): 376.80\n","----------------------------------------------------------------\n"]}],"source":["# load the model\n","resnet50 = models.resnet50(pretrained=True)\n","\n","# get layers\n","def slice_model(original_model, from_layer=None, to_layer=None):\n","    return nn.Sequential(*list(original_model.children())[from_layer:to_layer])\n","\n","model_conv_features = slice_model(resnet50, to_layer=-1).to(\"cpu\")\n","summary(model_conv_features, input_size=(3,224,224))"]},{"cell_type":"markdown","metadata":{"id":"o7GG96Qvoa54"},"source":["# Part 2 -- Extract Features From A Few Images\n","\n","Using the first 20 images per class, extract and store embedding features for each image.\n","\n"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"ndFMQh41TXYb"},"outputs":[],"source":["# preprocess\n","preprocess = transforms.Compose([\n","    transforms.Resize(256),\n","    transforms.CenterCrop(224),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225])\n","])\n","\n","def retype_image(in_img):\n","    if np.max(in_img) > 1:\n","       in_img = in_img.astype(np.uint8)\n","    else:\n","        in_img = (in_img * 255.0).astype(np.uint8)\n","    return in_img"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"tYNkYR9yVXJ-"},"outputs":[{"data":{"text/plain":["ResNet(\n","  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (relu): ReLU(inplace=True)\n","  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  (layer1): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (layer2): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (3): Bottleneck(\n","      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (layer3): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (3): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (4): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (5): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (layer4): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",")"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["# put the nn in evaluation mode\n","resnet50.eval()"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"NQBSumzgsp8H"},"outputs":[{"name":"stdout","output_type":"stream","text":["(2048,)\n"]}],"source":["fname = sorted(glob(subfolders[0] + \"/*.jpg\"))[0]\n","test_img = plt.imread(fname)\n","\n","proc_img = preprocess(Image.fromarray(retype_image(test_img)))\n","emb = model_conv_features(proc_img.unsqueeze(0).to(\"cpu\")).squeeze().detach().numpy()\n","print(emb.shape)"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[],"source":["# train model on new features produced by pretrained network\n","num_per_class = 20\n","\n","features = []\n","labels = []\n","\n","for i in range(len(subfolders)):\n","    fnames = sorted(glob(subfolders[i] + \"/*.jpg\"))\n","\n","    for j in range(num_per_class):\n","        img = plt.imread(fnames[j])\n","        proc_img = preprocess(Image.fromarray(retype_image(img)))\n","        feat = model_conv_features(proc_img.unsqueeze(0).to(\"cpu\")).squeeze().detach().numpy()\n","        \n","        labels.append(i)\n","        features.append(feat)\n"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["(120, 2048)\n"]}],"source":["features = np.array(features)\n","labels = np.array(labels)\n","\n","print(features.shape)"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy: 0.75\n"]}],"source":["X_train, X_test, y_train, y_test = train_test_split(\n","    features,\n","    labels,\n","    test_size = 0.2,\n","    stratify=labels,\n","    random_state=0\n",")\n","\n","clf = make_pipeline(StandardScaler(), SVC(gamma=\"auto\"))\n","clf.fit(X_train, y_train)\n","\n","y_pred = clf.predict(X_test)\n","print(f\"Accuracy: {clf.score(X_test, y_test)}\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[{"file_id":"1JzprN3bJ7DKquqcIKPel_DqPLtqRN-mL","timestamp":1708617641860}]},"kernelspec":{"display_name":"Python 3.11.6 ('.venv': poetry)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.6"},"vscode":{"interpreter":{"hash":"81e6f2adef2a5e1d5ced1040cf3fdfb2baa4a7bd70b935b2d6caba7994b1aa88"}}},"nbformat":4,"nbformat_minor":0}
